----------------------------------------ARGUMENTS----------------------------------------
data_dir                                 ./data/toys/
model_version                            0
task_num                                 3
prompt_num                               10
lr                                       0.0005
epochs                                   100
batch_size                               64
cuda                                     True
log_interval                             200
checkpoint                               ./checkpoint/toys/
endure_times                             5
exp_len                                  20
negative_num                             99
----------------------------------------ARGUMENTS----------------------------------------
[2023-05-17 22:09:43.386514]: Loading data
[2023-05-17 22:10:39.079189]: Start training
[2023-05-17 22:10:39.079530]: epoch 1
[2023-05-17 22:11:44.820945]: text loss 2.6935 |   200/ 1886 batches
[2023-05-17 22:12:50.872992]: text loss 2.2423 |   400/ 1886 batches
[2023-05-17 22:13:57.328288]: text loss 2.1919 |   600/ 1886 batches
[2023-05-17 22:15:02.997638]: text loss 2.1746 |   800/ 1886 batches
[2023-05-17 22:16:08.989131]: text loss 2.1361 |  1000/ 1886 batches
[2023-05-17 22:17:15.503525]: text loss 2.1305 |  1200/ 1886 batches
[2023-05-17 22:18:21.285182]: text loss 2.1259 |  1400/ 1886 batches
[2023-05-17 22:19:27.702203]: text loss 2.1174 |  1600/ 1886 batches
[2023-05-17 22:20:33.908760]: text loss 2.1053 |  1800/ 1886 batches
[2023-05-17 22:21:01.966006]: text loss 2.1023 |  1886/ 1886 batches
[2023-05-17 22:21:01.967617]: validation
[2023-05-17 22:21:05.683726]: explanation loss 2.2696
[2023-05-17 22:21:23.986527]: sequential loss 2.3495
[2023-05-17 22:23:07.717283]: top-N loss 1.5725
[2023-05-17 22:23:07.720304]: total loss 2.0639
[2023-05-17 22:23:08.549603]: epoch 2
[2023-05-17 22:23:46.288894]: text loss 2.1113 |  2000/ 1886 batches
[2023-05-17 22:24:52.265621]: text loss 2.0918 |  2200/ 1886 batches
[2023-05-17 22:25:57.825347]: text loss 2.1141 |  2400/ 1886 batches
[2023-05-17 22:27:03.206288]: text loss 2.0990 |  2600/ 1886 batches
[2023-05-17 22:28:09.050002]: text loss 2.0946 |  2800/ 1886 batches
[2023-05-17 22:29:15.151701]: text loss 2.1041 |  3000/ 1886 batches
[2023-05-17 22:30:20.526733]: text loss 2.1010 |  3200/ 1886 batches
[2023-05-17 22:31:26.590507]: text loss 2.0936 |  3400/ 1886 batches
[2023-05-17 22:32:32.178964]: text loss 2.1004 |  3600/ 1886 batches
[2023-05-17 22:33:28.725346]: text loss 2.1065 |  3772/ 1886 batches
[2023-05-17 22:33:28.732250]: validation
[2023-05-17 22:33:32.485152]: explanation loss 2.2274
[2023-05-17 22:33:50.549825]: sequential loss 2.3164
[2023-05-17 22:35:33.588071]: top-N loss 1.4995
[2023-05-17 22:35:33.588358]: total loss 2.0144
[2023-05-17 22:35:34.351308]: epoch 3
[2023-05-17 22:35:43.483859]: text loss 2.1603 |  3800/ 1886 batches
[2023-05-17 22:36:49.493340]: text loss 2.0540 |  4000/ 1886 batches
[2023-05-17 22:37:56.029098]: text loss 2.0437 |  4200/ 1886 batches
[2023-05-17 22:39:02.181149]: text loss 2.0306 |  4400/ 1886 batches
[2023-05-17 22:40:08.550986]: text loss 2.0236 |  4600/ 1886 batches
[2023-05-17 22:41:15.321127]: text loss 2.0386 |  4800/ 1886 batches
[2023-05-17 22:42:19.495230]: text loss 2.0343 |  5000/ 1886 batches
[2023-05-17 22:43:23.625188]: text loss 2.0294 |  5200/ 1886 batches
[2023-05-17 22:44:28.310778]: text loss 2.0257 |  5400/ 1886 batches
[2023-05-17 22:45:32.456453]: text loss 2.0234 |  5600/ 1886 batches
[2023-05-17 22:45:52.037002]: text loss 2.0024 |  5658/ 1886 batches
[2023-05-17 22:45:52.038471]: validation
[2023-05-17 22:45:55.764307]: explanation loss 2.1880
[2023-05-17 22:46:14.422455]: sequential loss 2.2966
[2023-05-17 22:47:58.729732]: top-N loss 1.4845
[2023-05-17 22:47:58.730018]: total loss 1.9897
[2023-05-17 22:47:59.583785]: epoch 4
[2023-05-17 22:48:46.379596]: text loss 2.0274 |  5800/ 1886 batches
[2023-05-17 22:49:52.877312]: text loss 2.0150 |  6000/ 1886 batches
[2023-05-17 22:50:58.213926]: text loss 2.0169 |  6200/ 1886 batches
[2023-05-17 22:52:04.521464]: text loss 2.0113 |  6400/ 1886 batches
[2023-05-17 22:53:11.077313]: text loss 2.0002 |  6600/ 1886 batches
[2023-05-17 22:54:17.350967]: text loss 2.0048 |  6800/ 1886 batches
[2023-05-17 22:55:23.931488]: text loss 2.0129 |  7000/ 1886 batches
[2023-05-17 22:56:30.399937]: text loss 2.0170 |  7200/ 1886 batches
[2023-05-17 22:57:35.964121]: text loss 2.0080 |  7400/ 1886 batches
[2023-05-17 22:58:22.996913]: text loss 2.0086 |  7544/ 1886 batches
[2023-05-17 22:58:22.998189]: validation
[2023-05-17 22:58:26.856041]: explanation loss 2.1677
[2023-05-17 22:58:45.321141]: sequential loss 2.2823
[2023-05-17 23:00:29.322609]: top-N loss 1.4716
[2023-05-17 23:00:29.323900]: total loss 1.9738
[2023-05-17 23:00:30.554033]: epoch 5
[2023-05-17 23:00:49.465719]: text loss 1.9932 |  7600/ 1886 batches
[2023-05-17 23:01:55.772845]: text loss 1.9886 |  7800/ 1886 batches
[2023-05-17 23:03:01.617889]: text loss 1.9905 |  8000/ 1886 batches
[2023-05-17 23:04:07.529498]: text loss 1.9729 |  8200/ 1886 batches
[2023-05-17 23:05:13.888683]: text loss 1.9809 |  8400/ 1886 batches
[2023-05-17 23:06:19.536446]: text loss 1.9786 |  8600/ 1886 batches
[2023-05-17 23:07:25.400821]: text loss 1.9718 |  8800/ 1886 batches
[2023-05-17 23:08:31.470616]: text loss 1.9741 |  9000/ 1886 batches
[2023-05-17 23:09:37.742971]: text loss 1.9867 |  9200/ 1886 batches
[2023-05-17 23:10:41.410848]: text loss 1.9633 |  9400/ 1886 batches
[2023-05-17 23:10:50.224689]: text loss 1.9718 |  9430/ 1886 batches
[2023-05-17 23:10:50.226032]: validation
[2023-05-17 23:10:53.717338]: explanation loss 2.1578
[2023-05-17 23:11:10.632296]: sequential loss 2.2694
[2023-05-17 23:12:42.121505]: top-N loss 1.4603
[2023-05-17 23:12:42.121981]: total loss 1.9625
[2023-05-17 23:12:42.944352]: epoch 6
[2023-05-17 23:13:31.758977]: text loss 1.9763 |  9600/ 1886 batches
[2023-05-17 23:14:33.793404]: text loss 1.9752 |  9800/ 1886 batches
[2023-05-17 23:15:40.180674]: text loss 1.9775 | 10000/ 1886 batches
[2023-05-17 23:16:46.425549]: text loss 1.9589 | 10200/ 1886 batches
[2023-05-17 23:17:51.579489]: text loss 1.9751 | 10400/ 1886 batches
[2023-05-17 23:18:57.600059]: text loss 1.9714 | 10600/ 1886 batches
[2023-05-17 23:20:03.622160]: text loss 1.9719 | 10800/ 1886 batches
[2023-05-17 23:21:09.043655]: text loss 1.9610 | 11000/ 1886 batches
[2023-05-17 23:22:14.951553]: text loss 1.9513 | 11200/ 1886 batches
[2023-05-17 23:22:53.455565]: text loss 1.9508 | 11316/ 1886 batches
[2023-05-17 23:22:53.456772]: validation
[2023-05-17 23:22:57.277350]: explanation loss 2.1460
[2023-05-17 23:23:15.327372]: sequential loss 2.2556
[2023-05-17 23:24:59.252816]: top-N loss 1.4478
[2023-05-17 23:24:59.253736]: total loss 1.9498
[2023-05-17 23:25:00.125633]: epoch 7
[2023-05-17 23:25:27.545761]: text loss 1.9515 | 11400/ 1886 batches
[2023-05-17 23:26:33.716642]: text loss 1.9652 | 11600/ 1886 batches
[2023-05-17 23:27:39.398000]: text loss 1.9346 | 11800/ 1886 batches
[2023-05-17 23:28:45.657902]: text loss 1.9458 | 12000/ 1886 batches
[2023-05-17 23:29:51.270266]: text loss 1.9373 | 12200/ 1886 batches
[2023-05-17 23:30:57.313033]: text loss 1.9610 | 12400/ 1886 batches
[2023-05-17 23:32:02.727950]: text loss 1.9501 | 12600/ 1886 batches
[2023-05-17 23:33:08.648133]: text loss 1.9479 | 12800/ 1886 batches
[2023-05-17 23:34:14.501283]: text loss 1.9387 | 13000/ 1886 batches
[2023-05-17 23:35:21.104420]: text loss 1.9454 | 13200/ 1886 batches
[2023-05-17 23:35:21.364319]: text loss 2.1121 | 13202/ 1886 batches
[2023-05-17 23:35:21.365613]: validation
[2023-05-17 23:35:25.127111]: explanation loss 2.1388
[2023-05-17 23:35:43.229512]: sequential loss 2.2499
[2023-05-17 23:37:26.472188]: top-N loss 1.4282
[2023-05-17 23:37:26.472463]: total loss 1.9390
[2023-05-17 23:37:27.291300]: epoch 8
[2023-05-17 23:38:32.656981]: text loss 1.9376 | 13400/ 1886 batches
[2023-05-17 23:39:39.301580]: text loss 1.9255 | 13600/ 1886 batches
[2023-05-17 23:40:45.297643]: text loss 1.9345 | 13800/ 1886 batches
[2023-05-17 23:41:50.666377]: text loss 1.9456 | 14000/ 1886 batches
[2023-05-17 23:42:57.146995]: text loss 1.9185 | 14200/ 1886 batches
[2023-05-17 23:44:03.438404]: text loss 1.9257 | 14400/ 1886 batches
[2023-05-17 23:45:09.020380]: text loss 1.9417 | 14600/ 1886 batches
[2023-05-17 23:46:15.203371]: text loss 1.9195 | 14800/ 1886 batches
[2023-05-17 23:47:20.900632]: text loss 1.9381 | 15000/ 1886 batches
[2023-05-17 23:47:49.708125]: text loss 1.9262 | 15088/ 1886 batches
[2023-05-17 23:47:49.710822]: validation
[2023-05-17 23:47:53.496642]: explanation loss 2.1311
[2023-05-17 23:48:11.874738]: sequential loss 2.2378
[2023-05-17 23:49:54.850711]: top-N loss 1.4120
[2023-05-17 23:49:54.851054]: total loss 1.9270
[2023-05-17 23:49:55.690327]: epoch 9
[2023-05-17 23:50:32.037806]: text loss 1.9201 | 15200/ 1886 batches
[2023-05-17 23:51:38.084910]: text loss 1.9318 | 15400/ 1886 batches
[2023-05-17 23:52:44.215461]: text loss 1.9057 | 15600/ 1886 batches
[2023-05-17 23:53:49.102980]: text loss 1.9003 | 15800/ 1886 batches
[2023-05-17 23:54:55.290038]: text loss 1.9101 | 16000/ 1886 batches
[2023-05-17 23:56:01.332301]: text loss 1.9041 | 16200/ 1886 batches
[2023-05-17 23:57:06.776224]: text loss 1.9136 | 16400/ 1886 batches
[2023-05-17 23:58:11.824547]: text loss 1.9021 | 16600/ 1886 batches
[2023-05-17 23:59:18.330876]: text loss 1.9075 | 16800/ 1886 batches
[2023-05-18 00:00:16.059491]: text loss 1.9113 | 16974/ 1886 batches
[2023-05-18 00:00:16.060777]: validation
[2023-05-18 00:00:19.824549]: explanation loss 2.1277
[2023-05-18 00:00:38.362971]: sequential loss 2.2307
[2023-05-18 00:02:22.387478]: top-N loss 1.3871
[2023-05-18 00:02:22.390192]: total loss 1.9152
[2023-05-18 00:02:23.206254]: epoch 10
[2023-05-18 00:02:31.447355]: text loss 1.9319 | 17000/ 1886 batches
[2023-05-18 00:03:37.773072]: text loss 1.9006 | 17200/ 1886 batches
[2023-05-18 00:04:44.896745]: text loss 1.8992 | 17400/ 1886 batches
[2023-05-18 00:05:50.619405]: text loss 1.9077 | 17600/ 1886 batches
[2023-05-18 00:06:56.525760]: text loss 1.9156 | 17800/ 1886 batches
[2023-05-18 00:08:02.465262]: text loss 1.9044 | 18000/ 1886 batches
[2023-05-18 00:09:07.795241]: text loss 1.8903 | 18200/ 1886 batches
[2023-05-18 00:10:14.499032]: text loss 1.9081 | 18400/ 1886 batches
[2023-05-18 00:11:20.646035]: text loss 1.8967 | 18600/ 1886 batches
[2023-05-18 00:12:25.914027]: text loss 1.9059 | 18800/ 1886 batches
[2023-05-18 00:12:45.443555]: text loss 1.8885 | 18860/ 1886 batches
[2023-05-18 00:12:45.450820]: validation
[2023-05-18 00:12:49.481476]: explanation loss 2.1231
[2023-05-18 00:13:08.168757]: sequential loss 2.2276
[2023-05-18 00:14:52.131679]: top-N loss 1.3767
[2023-05-18 00:14:52.134320]: total loss 1.9091
[2023-05-18 00:14:53.021352]: epoch 11
[2023-05-18 00:15:39.053932]: text loss 1.8989 | 19000/ 1886 batches
[2023-05-18 00:16:45.633347]: text loss 1.8979 | 19200/ 1886 batches
[2023-05-18 00:17:51.701465]: text loss 1.8852 | 19400/ 1886 batches
[2023-05-18 00:18:58.076440]: text loss 1.8802 | 19600/ 1886 batches
[2023-05-18 00:20:03.908817]: text loss 1.8868 | 19800/ 1886 batches
[2023-05-18 00:21:09.406153]: text loss 1.8842 | 20000/ 1886 batches
[2023-05-18 00:22:15.267644]: text loss 1.8862 | 20200/ 1886 batches
[2023-05-18 00:23:21.060588]: text loss 1.8698 | 20400/ 1886 batches
[2023-05-18 00:24:26.811567]: text loss 1.8859 | 20600/ 1886 batches
[2023-05-18 00:25:15.870477]: text loss 1.8841 | 20746/ 1886 batches
[2023-05-18 00:25:15.879789]: validation
[2023-05-18 00:25:19.701579]: explanation loss 2.1229
[2023-05-18 00:25:38.082242]: sequential loss 2.2213
[2023-05-18 00:27:21.120206]: top-N loss 1.3594
[2023-05-18 00:27:21.123028]: total loss 1.9012
[2023-05-18 00:27:21.969454]: epoch 12
[2023-05-18 00:27:39.258524]: text loss 1.8835 | 20800/ 1886 batches
[2023-05-18 00:28:45.699901]: text loss 1.8776 | 21000/ 1886 batches
[2023-05-18 00:29:51.284630]: text loss 1.8813 | 21200/ 1886 batches
[2023-05-18 00:30:57.797767]: text loss 1.8736 | 21400/ 1886 batches
[2023-05-18 00:32:03.425660]: text loss 1.8825 | 21600/ 1886 batches
[2023-05-18 00:33:08.785837]: text loss 1.8858 | 21800/ 1886 batches
[2023-05-18 00:34:14.811647]: text loss 1.8656 | 22000/ 1886 batches
[2023-05-18 00:35:20.703610]: text loss 1.8732 | 22200/ 1886 batches
[2023-05-18 00:36:26.575807]: text loss 1.8859 | 22400/ 1886 batches
[2023-05-18 00:37:32.472869]: text loss 1.8790 | 22600/ 1886 batches
[2023-05-18 00:37:43.288271]: text loss 1.8815 | 22632/ 1886 batches
[2023-05-18 00:37:43.289567]: validation
[2023-05-18 00:37:47.066268]: explanation loss 2.1180
[2023-05-18 00:38:05.463032]: sequential loss 2.2209
[2023-05-18 00:39:48.787823]: top-N loss 1.3589
[2023-05-18 00:39:48.788199]: total loss 1.8993
[2023-05-18 00:39:49.636318]: epoch 13
[2023-05-18 00:40:45.590800]: text loss 1.8743 | 22800/ 1886 batches
[2023-05-18 00:41:51.136190]: text loss 1.8721 | 23000/ 1886 batches
[2023-05-18 00:42:57.358335]: text loss 1.8572 | 23200/ 1886 batches
[2023-05-18 00:44:03.178351]: text loss 1.8586 | 23400/ 1886 batches
[2023-05-18 00:45:07.947019]: text loss 1.8649 | 23600/ 1886 batches
[2023-05-18 00:46:13.944589]: text loss 1.8545 | 23800/ 1886 batches
[2023-05-18 00:47:19.698290]: text loss 1.8540 | 24000/ 1886 batches
[2023-05-18 00:48:25.540744]: text loss 1.8610 | 24200/ 1886 batches
[2023-05-18 00:49:31.242432]: text loss 1.8482 | 24400/ 1886 batches
[2023-05-18 00:50:09.934677]: text loss 1.8725 | 24518/ 1886 batches
[2023-05-18 00:50:09.935647]: validation
[2023-05-18 00:50:14.040795]: explanation loss 2.1208
[2023-05-18 00:50:33.018361]: sequential loss 2.2181
[2023-05-18 00:52:16.149452]: top-N loss 1.3363
[2023-05-18 00:52:16.150969]: total loss 1.8917
[2023-05-18 00:52:16.994744]: epoch 14
[2023-05-18 00:52:44.409563]: text loss 1.8487 | 24600/ 1886 batches
[2023-05-18 00:53:49.607024]: text loss 1.8472 | 24800/ 1886 batches
[2023-05-18 00:54:56.324036]: text loss 1.8520 | 25000/ 1886 batches
[2023-05-18 00:56:02.514271]: text loss 1.8576 | 25200/ 1886 batches
[2023-05-18 00:57:07.460668]: text loss 1.8595 | 25400/ 1886 batches
[2023-05-18 00:58:13.676962]: text loss 1.8610 | 25600/ 1886 batches
[2023-05-18 00:59:19.622026]: text loss 1.8654 | 25800/ 1886 batches
[2023-05-18 01:00:25.076061]: text loss 1.8627 | 26000/ 1886 batches
[2023-05-18 01:01:31.249385]: text loss 1.8539 | 26200/ 1886 batches
[2023-05-18 01:02:37.728162]: text loss 1.8572 | 26400/ 1886 batches
[2023-05-18 01:02:38.784904]: text loss 1.8318 | 26404/ 1886 batches
[2023-05-18 01:02:38.785809]: validation
[2023-05-18 01:02:42.586919]: explanation loss 2.1194
[2023-05-18 01:03:01.380654]: sequential loss 2.2238
[2023-05-18 01:04:45.054382]: top-N loss 1.3429
[2023-05-18 01:04:45.054665]: total loss 1.8953
[2023-05-18 01:04:45.054687]: Endured 1 time(s)
[2023-05-18 01:04:45.054706]: epoch 15
[2023-05-18 01:05:49.290013]: text loss 1.8535 | 26600/ 1886 batches
[2023-05-18 01:06:55.749215]: text loss 1.8454 | 26800/ 1886 batches
[2023-05-18 01:08:01.826402]: text loss 1.8438 | 27000/ 1886 batches
[2023-05-18 01:09:07.005358]: text loss 1.8484 | 27200/ 1886 batches
[2023-05-18 01:10:13.133640]: text loss 1.8272 | 27400/ 1886 batches
[2023-05-18 01:11:19.259554]: text loss 1.8462 | 27600/ 1886 batches
[2023-05-18 01:12:22.655876]: text loss 1.8429 | 27800/ 1886 batches
[2023-05-18 01:13:26.343538]: text loss 1.8445 | 28000/ 1886 batches
[2023-05-18 01:14:30.469864]: text loss 1.8332 | 28200/ 1886 batches
[2023-05-18 01:14:59.031141]: text loss 1.8470 | 28290/ 1886 batches
[2023-05-18 01:14:59.032110]: validation
[2023-05-18 01:15:02.868986]: explanation loss 2.1205
[2023-05-18 01:15:21.227121]: sequential loss 2.2182
[2023-05-18 01:16:58.566607]: top-N loss 1.3338
[2023-05-18 01:16:58.566961]: total loss 1.8908
[2023-05-18 01:16:59.705716]: epoch 16
[2023-05-18 01:17:34.386172]: text loss 1.8539 | 28400/ 1886 batches
[2023-05-18 01:18:38.593038]: text loss 1.8351 | 28600/ 1886 batches
[2023-05-18 01:19:42.805563]: text loss 1.8341 | 28800/ 1886 batches
[2023-05-18 01:20:46.886203]: text loss 1.8360 | 29000/ 1886 batches
[2023-05-18 01:21:51.035959]: text loss 1.8393 | 29200/ 1886 batches
[2023-05-18 01:22:55.357119]: text loss 1.8385 | 29400/ 1886 batches
[2023-05-18 01:23:58.926473]: text loss 1.8306 | 29600/ 1886 batches
[2023-05-18 01:25:02.793335]: text loss 1.8432 | 29800/ 1886 batches
[2023-05-18 01:26:06.956704]: text loss 1.8346 | 30000/ 1886 batches
[2023-05-18 01:27:02.870569]: text loss 1.8311 | 30176/ 1886 batches
[2023-05-18 01:27:02.871487]: validation
[2023-05-18 01:27:06.815704]: explanation loss 2.1162
[2023-05-18 01:27:24.697108]: sequential loss 2.2204
[2023-05-18 01:29:02.353468]: top-N loss 1.3347
[2023-05-18 01:29:02.353810]: total loss 1.8904
[2023-05-18 01:29:03.081217]: epoch 17
[2023-05-18 01:29:10.898025]: text loss 1.8226 | 30200/ 1886 batches
[2023-05-18 01:30:16.562591]: text loss 1.8356 | 30400/ 1886 batches
[2023-05-18 01:31:21.736291]: text loss 1.8333 | 30600/ 1886 batches
[2023-05-18 01:32:19.760942]: text loss 1.8224 | 30800/ 1886 batches
[2023-05-18 01:33:16.053999]: text loss 1.8029 | 31000/ 1886 batches
[2023-05-18 01:34:12.332245]: text loss 1.8226 | 31200/ 1886 batches
[2023-05-18 01:35:08.177701]: text loss 1.8239 | 31400/ 1886 batches
[2023-05-18 01:36:12.248817]: text loss 1.8225 | 31600/ 1886 batches
[2023-05-18 01:37:16.569603]: text loss 1.8122 | 31800/ 1886 batches
[2023-05-18 01:38:20.285317]: text loss 1.8150 | 32000/ 1886 batches
[2023-05-18 01:38:40.167019]: text loss 1.7955 | 32062/ 1886 batches
[2023-05-18 01:38:40.168438]: validation
[2023-05-18 01:38:44.060096]: explanation loss 2.1188
[2023-05-18 01:39:02.363975]: sequential loss 2.2240
[2023-05-18 01:40:40.001698]: top-N loss 1.3173
[2023-05-18 01:40:40.002060]: total loss 1.8867
[2023-05-18 01:40:40.779359]: epoch 18
[2023-05-18 01:41:24.784791]: text loss 1.8198 | 32200/ 1886 batches
[2023-05-18 01:42:29.367042]: text loss 1.8182 | 32400/ 1886 batches
[2023-05-18 01:43:33.358697]: text loss 1.8189 | 32600/ 1886 batches
[2023-05-18 01:44:38.353755]: text loss 1.8193 | 32800/ 1886 batches
[2023-05-18 01:45:42.587943]: text loss 1.8159 | 33000/ 1886 batches
[2023-05-18 01:46:47.299755]: text loss 1.8139 | 33200/ 1886 batches
[2023-05-18 01:47:52.044428]: text loss 1.8097 | 33400/ 1886 batches
[2023-05-18 01:48:56.702352]: text loss 1.8219 | 33600/ 1886 batches
[2023-05-18 01:50:00.409071]: text loss 1.8259 | 33800/ 1886 batches
[2023-05-18 01:50:48.054159]: text loss 1.8087 | 33948/ 1886 batches
[2023-05-18 01:50:48.055078]: validation
[2023-05-18 01:50:51.903156]: explanation loss 2.1140
[2023-05-18 01:51:09.887261]: sequential loss 2.2219
[2023-05-18 01:52:47.357321]: top-N loss 1.3174
[2023-05-18 01:52:47.357631]: total loss 1.8844
[2023-05-18 01:52:48.166935]: epoch 19
[2023-05-18 01:53:04.567598]: text loss 1.8356 | 34000/ 1886 batches
[2023-05-18 01:54:08.816232]: text loss 1.8198 | 34200/ 1886 batches
[2023-05-18 01:55:12.819945]: text loss 1.8259 | 34400/ 1886 batches
[2023-05-18 01:56:17.030205]: text loss 1.8233 | 34600/ 1886 batches
[2023-05-18 01:57:21.769695]: text loss 1.8030 | 34800/ 1886 batches
[2023-05-18 01:58:25.301414]: text loss 1.8005 | 35000/ 1886 batches
[2023-05-18 01:59:29.559562]: text loss 1.8040 | 35200/ 1886 batches
[2023-05-18 02:00:33.027772]: text loss 1.7988 | 35400/ 1886 batches
[2023-05-18 02:01:36.783019]: text loss 1.7999 | 35600/ 1886 batches
[2023-05-18 02:02:41.321238]: text loss 1.7933 | 35800/ 1886 batches
[2023-05-18 02:02:51.914603]: text loss 1.8128 | 35834/ 1886 batches
[2023-05-18 02:02:51.915403]: validation
[2023-05-18 02:02:55.953842]: explanation loss 2.1237
[2023-05-18 02:03:13.930191]: sequential loss 2.2213
[2023-05-18 02:04:51.385079]: top-N loss 1.3160
[2023-05-18 02:04:51.385333]: total loss 1.8870
[2023-05-18 02:04:51.385355]: Endured 2 time(s)
[2023-05-18 02:04:51.385367]: epoch 20
[2023-05-18 02:05:44.711346]: text loss 1.8020 | 36000/ 1886 batches
[2023-05-18 02:06:47.848245]: text loss 1.8026 | 36200/ 1886 batches
[2023-05-18 02:07:51.796578]: text loss 1.7955 | 36400/ 1886 batches
[2023-05-18 02:08:56.052970]: text loss 1.7918 | 36600/ 1886 batches
[2023-05-18 02:09:59.739188]: text loss 1.8096 | 36800/ 1886 batches
[2023-05-18 02:11:03.496085]: text loss 1.7997 | 37000/ 1886 batches
[2023-05-18 02:12:07.921110]: text loss 1.7890 | 37200/ 1886 batches
[2023-05-18 02:13:11.389617]: text loss 1.8002 | 37400/ 1886 batches
[2023-05-18 02:14:16.040880]: text loss 1.7932 | 37600/ 1886 batches
[2023-05-18 02:14:55.263151]: text loss 1.7812 | 37720/ 1886 batches
[2023-05-18 02:14:55.264056]: validation
[2023-05-18 02:14:59.163939]: explanation loss 2.1167
[2023-05-18 02:15:18.175622]: sequential loss 2.2210
[2023-05-18 02:16:56.273140]: top-N loss 1.3055
[2023-05-18 02:16:56.273449]: total loss 1.8811
[2023-05-18 02:16:57.043079]: epoch 21
[2023-05-18 02:17:23.393238]: text loss 1.7925 | 37800/ 1886 batches
[2023-05-18 02:18:27.288280]: text loss 1.7975 | 38000/ 1886 batches
[2023-05-18 02:19:32.402758]: text loss 1.8026 | 38200/ 1886 batches
[2023-05-18 02:20:37.934019]: text loss 1.7916 | 38400/ 1886 batches
[2023-05-18 02:21:42.739510]: text loss 1.7763 | 38600/ 1886 batches
[2023-05-18 02:22:47.186995]: text loss 1.7751 | 38800/ 1886 batches
[2023-05-18 02:23:51.497879]: text loss 1.7767 | 39000/ 1886 batches
[2023-05-18 02:24:55.378189]: text loss 1.7860 | 39200/ 1886 batches
[2023-05-18 02:25:59.651522]: text loss 1.7724 | 39400/ 1886 batches
[2023-05-18 02:27:03.941891]: text loss 1.7768 | 39600/ 1886 batches
[2023-05-18 02:27:05.845103]: text loss 1.7384 | 39606/ 1886 batches
[2023-05-18 02:27:05.845950]: validation
[2023-05-18 02:27:09.662158]: explanation loss 2.1234
[2023-05-18 02:27:27.837199]: sequential loss 2.2241
[2023-05-18 02:29:05.508629]: top-N loss 1.3099
[2023-05-18 02:29:05.509045]: total loss 1.8858
[2023-05-18 02:29:05.509065]: Endured 3 time(s)
[2023-05-18 02:29:05.509076]: epoch 22
[2023-05-18 02:30:06.951206]: text loss 1.7889 | 39800/ 1886 batches
[2023-05-18 02:31:11.119078]: text loss 1.7964 | 40000/ 1886 batches
[2023-05-18 02:32:15.249926]: text loss 1.7814 | 40200/ 1886 batches
[2023-05-18 02:33:19.375299]: text loss 1.7801 | 40400/ 1886 batches
[2023-05-18 02:34:23.672728]: text loss 1.7778 | 40600/ 1886 batches
[2023-05-18 02:35:28.254636]: text loss 1.7787 | 40800/ 1886 batches
[2023-05-18 02:36:31.877907]: text loss 1.7854 | 41000/ 1886 batches
[2023-05-18 02:37:36.029702]: text loss 1.7755 | 41200/ 1886 batches
[2023-05-18 02:38:41.403142]: text loss 1.7725 | 41400/ 1886 batches
[2023-05-18 02:39:10.542860]: text loss 1.7717 | 41492/ 1886 batches
[2023-05-18 02:39:10.543702]: validation
[2023-05-18 02:39:14.385294]: explanation loss 2.1154
[2023-05-18 02:39:32.421859]: sequential loss 2.2268
[2023-05-18 02:41:10.033861]: top-N loss 1.3069
[2023-05-18 02:41:10.034195]: total loss 1.8830
[2023-05-18 02:41:10.034216]: Endured 4 time(s)
[2023-05-18 02:41:10.034227]: epoch 23
[2023-05-18 02:41:44.313666]: text loss 1.7733 | 41600/ 1886 batches
[2023-05-18 02:42:48.330852]: text loss 1.7839 | 41800/ 1886 batches
[2023-05-18 02:43:53.063002]: text loss 1.7784 | 42000/ 1886 batches
[2023-05-18 02:44:56.988534]: text loss 1.7701 | 42200/ 1886 batches
[2023-05-18 02:46:01.741732]: text loss 1.7526 | 42400/ 1886 batches
[2023-05-18 02:47:05.875535]: text loss 1.7576 | 42600/ 1886 batches
[2023-05-18 02:48:09.803575]: text loss 1.7554 | 42800/ 1886 batches
[2023-05-18 02:49:14.078548]: text loss 1.7528 | 43000/ 1886 batches
[2023-05-18 02:50:18.252982]: text loss 1.7652 | 43200/ 1886 batches
[2023-05-18 02:51:15.588949]: text loss 1.7589 | 43378/ 1886 batches
[2023-05-18 02:51:15.589854]: validation
[2023-05-18 02:51:19.502272]: explanation loss 2.1252
[2023-05-18 02:51:38.307449]: sequential loss 2.2305
[2023-05-18 02:53:16.722122]: top-N loss 1.2978
[2023-05-18 02:53:16.722469]: total loss 1.8845
[2023-05-18 02:53:16.722490]: Endured 5 time(s)
[2023-05-18 02:53:16.722503]: Cannot endure it anymore | Exiting from early stop
----------------------------------------ARGUMENTS----------------------------------------
data_dir                                 ./data/toys/
model_version                            0
batch_size                               32
cuda                                     True
checkpoint                               ./checkpoint/toys/
seq_len                                  50
num_beams                                20
top_n                                    10
----------------------------------------ARGUMENTS----------------------------------------
[2023-05-18 03:02:56.480122]: Loading data
[2023-05-18 03:03:29.693067]: Generating recommendations
[2023-05-18 03:17:29.804894]: HR@1  0.0515
[2023-05-18 03:17:29.815802]: NDCG@1  0.0515
[2023-05-18 03:17:29.825299]: HR@5  0.0691
[2023-05-18 03:17:29.838578]: NDCG@5  0.0599
[2023-05-18 03:17:29.850567]: HR@10  0.0742
[2023-05-18 03:17:29.867351]: NDCG@10  0.0610
----------------------------------------ARGUMENTS----------------------------------------
data_dir                                 ./data/toys/
model_version                            0
batch_size                               32
cuda                                     True
checkpoint                               ./checkpoint/toys/
negative_num                             99
seq_len                                  50
num_beams                                20
top_n                                    10
----------------------------------------ARGUMENTS----------------------------------------
[2023-05-18 03:17:31.320926]: Loading data
[2023-05-18 03:17:58.811457]: Generating recommendations
[2023-05-18 03:48:23.223190]: HR@1  0.0567
[2023-05-18 03:48:23.234625]: NDCG@1  0.0567
[2023-05-18 03:48:23.244468]: HR@5  0.1433
[2023-05-18 03:48:23.258561]: NDCG@5  0.1009
[2023-05-18 03:48:23.270855]: HR@10  0.2082
[2023-05-18 03:48:23.288687]: NDCG@10  0.1215
----------------------------------------ARGUMENTS----------------------------------------
data_dir                                 ./data/toys/
model_version                            0
batch_size                               32
cuda                                     True
checkpoint                               ./checkpoint/toys/
outf                                     generated.txt
exp_len                                  20
----------------------------------------ARGUMENTS----------------------------------------
[2023-05-21 01:00:31.155164]: Loading data
[2023-05-21 01:00:39.194040]: Generating text
[2023-05-21 01:08:02.326875]: BLEU-1 12.2579
[2023-05-21 01:08:03.194114]: BLEU-4  2.3053
[2023-05-21 01:08:04.258009]: rouge_1/f_score 12.2889
[2023-05-21 01:08:04.258078]: rouge_1/r_score 12.2368
[2023-05-21 01:08:04.258089]: rouge_1/p_score 13.2610
[2023-05-21 01:08:04.258097]: rouge_2/f_score  3.8512
[2023-05-21 01:08:04.258105]: rouge_2/r_score  4.0208
[2023-05-21 01:08:04.258112]: rouge_2/p_score  4.0240
[2023-05-21 01:08:04.258119]: rouge_l/f_score 10.3923
[2023-05-21 01:08:04.258126]: rouge_l/r_score 11.4007
[2023-05-21 01:08:04.258133]: rouge_l/p_score 11.4895
[2023-05-21 01:08:04.267409]: Generated text saved to (./checkpoint/toys/generated.txt)
